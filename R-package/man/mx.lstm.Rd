% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/lstm.R
\name{mx.lstm}
\alias{mx.lstm}
\title{Training LSTM Unrolled Model}
\usage{
mx.lstm(train.data, eval.data = NULL, num.lstm.layer, seq.len, num.hidden,
  num.embed, num.label, batch.size, input.size, ctx = mx.ctx.default(),
  num.round = 10, update.period = 1, initializer = mx.init.uniform(0.01),
  dropout = 0, optimizer = "sgd", ...)
}
\arguments{
\item{train.data}{mx.io.DataIter or list(data=R.array, label=R.array)
The Training set.}

\item{eval.data}{mx.io.DataIter or list(data=R.array, label=R.array), optional
The validation set used for validation evaluation during the progress.}

\item{num.lstm.layer}{integer
The number of the layer of lstm.}

\item{seq.len}{integer
The length of the input sequence.}

\item{num.hidden}{integer
The number of hidden nodes.}

\item{num.embed}{integer
The output dim of embedding.}

\item{num.label}{integer
The number of labels.}

\item{batch.size}{integer
The batch size used for R array training.}

\item{input.size}{integer
The input dim of one-hot encoding of embedding}

\item{ctx}{mx.context, optional
The device used to perform training.}

\item{num.round}{integer, default=10
The number of iterations over training data to train the model.}

\item{update.period}{integer, default=1
The number of iterations to update parameters during training period.}

\item{initializer}{initializer object. default=mx.init.uniform(0.01)
The initialization scheme for parameters.}

\item{dropout}{float, default=0
A number in [0,1) containing the dropout ratio from the last hidden layer to the output layer.}

\item{optimizer}{string, default="sgd"
The optimization method.}

\item{...}{other parameters passing to \code{mx.lstm}/.}
}
\value{
model A trained lstm unrolled model.
}
\description{
Training LSTM Unrolled Model
}

